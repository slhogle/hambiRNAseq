---
title: "Modeling effects of _Pseudomonas_ evolution on total ATP concentration"
output: 
  html_notebook
---

<!-- output:  -->
<!--   github_document: -->
<!--     toc: yes -->
<!--     toc_depth: 2 -->
<!--     fig_width: 7 -->
<!--     fig_height: 5 -->
<!--     dev: png -->
<!--     keep_html: yes -->
<!--     html_preview: yes -->
    
```{r echo=TRUE, message=FALSE, warning=FALSE}
library(here)
library(tidyverse)
library(fitdistrplus)
```

# READ AND FORMAT
We started each bacterial species at 10<sup>6<sup/> cells per mL except for 
_Pseudomonas_ which we inoculated at 10<sup>7<sup/> cells per mL.

[useful post](https://stats.stackexchange.com/a/127559) for making dummy interaction variables
```{r message=FALSE, warning=FALSE}
metadata <- read_tsv(here("data", "metadata.tsv"), col_types="cfffffff") %>%
  mutate(pseudomonas_hist=factor(pseudomonas_hist, levels=c("ancestral", "coevolved")),
         tetra_hist=factor(tetra_hist, levels=c("no_tetra", "coevolved")))

atp <- read_tsv(here("data", "ATP_concentration.tsv"), col_types="cddddddddddd") %>%
  gather(day, value, -sample) %>%
  mutate(day=as.numeric(day)) 
```

setup the categorical vars. Scale response and finalize
```{r}
#setup the categorical vars
atp1 <- left_join(atp, metadata, by="sample") %>% 
  filter(pseudomonas_hist %in% c("ancestral", "coevolved")) %>%
  filter(tetra_hist %in% c("coevolved", "no_tetra")) %>%
  mutate(pred=ifelse(str_detect(tetra_hist, "coevolved"), "predation", "none"),
         evo=ifelse(str_detect(pseudomonas_hist, "coevolved"), "evolution", "none"),
         pred_evo=ifelse(str_detect(tetra_hist, "coevolved") & 
                           str_detect(pseudomonas_hist, "coevolved"), "interaction", "none")) %>%
  group_by(pred, evo, replicate) %>%
  mutate(id=dplyr::cur_group_id()) %>%
  ungroup()

# scale response var
atp2 <- atp1 %>%
  #group_by(id) %>%
  mutate(vallog=log10(value),   # for Gaussian
         count=ceiling(value),  # for beta binomial
         recoveryonset=day-43) %>%
  mutate(countred=ceiling(count/10000),
         vallogscale=scale(vallog)) %>%
  ungroup() 

# finalize data
atp3 <- atp2 %>%
  dplyr::select(pred, evo, pred_evo, recoveryonset, day, id, count, countred, vallog, vallogscale) %>%
  arrange(id, day) %>%
  mutate(pred=as.factor(pred),
         evo=as.factor(evo),
         pred_evo=as.factor(pred_evo),
         recoveryonset=as.numeric(recoveryonset),
         day=as.numeric(day), 
         id=as.factor(id),
         count=as.numeric(count),
         vallogscale=as.numeric(vallogscale)) %>%
  as.data.frame()

saveRDS(atp3, here::here("bin", "cluster", "atp3.rds"))
```

## Back transforming scaling
```{r}
sc <- scale(atp3$vallog)
atp3$backscale <- atp3$vallogscale * attr(sc, 'scaled:scale') + attr(sc, 'scaled:center')

scalescale <- attr(sc, 'scaled:scale')
scalecenter <- attr(sc, 'scaled:center')
```


```{r}
ggplot(atp3) + 
  geom_line(aes(x=day, y=vallogscale, group=id, color=evo)) +
  facet_grid(~pred) + 
  #scale_y_log10() + 
  theme_bw()
```
# BEST PROBABILITY DISTRIBUTIONS

Which probability distribution best fits the ATP data?

[This is a good, short explanation](https://stats.stackexchange.com/a/303592) 
for choosing the probability distribution. 

The two most relevant options in this case are NB and gaussian:
1. Gaussian: (a.k.a. normal distribution).
 - Continuous
 - Unbounded
2. Negative binomial
 - Continuous
 - Bounded, outcome is non-negative

```{r message=FALSE, warning=FALSE}
fit.n <- fitdist(atp3$vallogscale, "norm")
fit.ln <- fitdist(atp3$countred, "lnorm")
fit.nb <- fitdist(atp3$countred, "nbinom")
```

### Histograms and theoretical densities
```{r}
denscomp(fit.n, legendtext="scaled-Gaussian", probability = T)
```

```{r}
denscomp(fit.ln, legendtext="Log-gaussian", probability = T)
```

### Q-Q plots
```{r}
qqcomp(fit.n, legendtext="Scaled-gaussian")
```

```{r}
qqcomp(list(fit.ln, fit.nb),legendtext=c("Log-gaussian","Neg Binom"), xlogscale = T, ylogscale = T)
```

### Empirical and theoretical CDFs
```{r}
cdfcomp(fit.n, legendtext="Scaled-gaussian")
```

```{r}
cdfcomp(list(fit.ln,fit.nb),legendtext=c("Log-gaussian","Neg Binom"))
```

### Theoretical/empirical probs
```{r}
ppcomp(fit.n, legendtext="Scaled-gaussian")
```

```{r}
ppcomp(list(fit.ln,fit.nb),legendtext=c("Log-gaussian","Neg Binom"))
```

So both gaussian and Neg. binomial seems to fit fairly well. Will use gaussian with a log10 transform because it makes computation with Gaussian process regression more computationally straightforward and hence faster.

# MODELING
```{r}
library(lgpr)
```
## DEFINE PRIORS
 
### WARP STEEPNESS
Warp needs to be pretty steep since the change happens within 5 days or so. 

Setting mu to -0.1 and sigmap to 0.2 seems to achieve this effect
```{r}
num_draws <- 300
mu_wrp <- -0.1
sigma_wrp <- 0.2

r <- range(atp3$recoveryonset, na.rm = TRUE)

# Prior draws
wrp_draws <- stats::rlnorm(num_draws, mu_wrp, sigma_wrp)

# Plot corresponding input warping functions
# - this function is not exported from lgpr so we need to use triple colons :::
# - alpha here is line opacity, not a GP parameter
lgpr:::plot_inputwarp(wrp_draws, seq(r[1], r[2], by = 1), alpha = 0.1)
```
## ALPHA AND GAMMA 
Needed for using the beta-binomial distribution. To use beta-binomial observation model in our analysis, we use the likelihood argument of lgp(). Here we define a Beta(2,2) prior for the gamma parameter.

```{r}
my_prior.bb <- list(
              wrp = log_normal(-0.1, 0.2),
              alpha = student_t(20),
              gamma = bet(2, 2)
              )
```


## GAUSSIAN
run on cluster
```{r}
lgpinput <- atp3 %>% 
  dplyr::select(-count, -countred) %>%
  dplyr::rename(y=vallogscale)

my_prior.g <- list(
              wrp = log_normal(-0.1, 0.2)
              )

fit.g <- lgp(y ~ gp(day) + zs(id)*gp(day) + categ(pred)*gp(day) + categ(evo)*gp(day) + 
                categ(pred_evo)*gp(day) + gp_vm(recoveryonset),
              lgpinput, 
              likelihood = "gaussian",
              prior = my_prior.g,
              verbose = TRUE,
              refresh = 500,
              chains = 4,
              cores = 4,
              control = list(adapt_delta = 0.95),
              iter = 200)
```

### CATEGORICAL KERNELS FOR EVOLUTION, PREDATION, PRED_EVO
Read in the saved Stan object if coming back to this later
```{r}
fit.g <- readRDS(here::here("output", "fit-atp-cat-gs.rds"))
```

#### CHECK POSTERIOR
```{r}
plot_draws(fit.g, type = 'dens')
```

#### COMPONENT RELEVANCES
```{r}
data.frame(relevances(fit.g, reduce = mean)) %>% 
  rownames_to_column(var="variable") %>% tibble()
```
```{r}
lgpr:::relevances.default.all(fit.g) %>% tibble() %>%
  pivot_longer(everything()) %>%
  ggplot(aes(x=name, y=value)) +
    geom_violin(scale="width")
```

```{r}
select(fit.g, threshold = 0.95)
```

```{r}
threshold_density <- function(x) {stats::dbeta(x, 20, 2)}
s <- select.integrate(fit.g, p = threshold_density)
print(s$expected)
```

```{r}
t <- seq(1, 55, by = 1)
x_pred <- new_x(lgpinput, t, x="day", x_ns = "recoveryonset")
p <- pred(fit.g, x_pred, reduce = mean)
plot_pred(fit.g, x = x_pred, pred = p, t_name="day", group_by=c("id"))
```

```{r}
plot_f(fit.g, x = x_pred, pred = p, t_name="day",  color_by="pred_evo")
```

```{r}
plot_components(fit.g,
                x = x_pred, 
                t_name = "day",
                group_by="id", 
                pred = p,
                color_by = c(NA, NA, "pred", "evo", "pred_evo", NA, "pred_evo"),
                #color_by="pred_evo",
                ylim = c(-3,2))
```

### ZERO-SUM KERNELS FOR EVOLUTION, PREDATION, PRED_EVO

Read in the saved Stan object if coming back to this later
```{r}
fit.g1 <- readRDS(here::here("output", "fit-atp-zs-gs.rds"))
```

#### CHECK POSTERIOR
```{r}
plot_draws(fit.g1, type = 'dens')
```

#### COMPONENT RELEVANCES
```{r}
data.frame(relevances(fit.g1, reduce = mean)) %>% 
  rownames_to_column(var="variable") %>% tibble()
```

```{r}
rel <- lgpr:::relevances.default.all(fit.g1) %>% tibble() %>%
  pivot_longer(everything()) %>%
  mutate(measure="atp")

thresh <- select(fit.g1, threshold = 0.95) %>% rownames_to_column(var="name") %>% tibble()

relf <- left_join(rel, thresh)

saveRDS(relf, here::here("output", "relevance_atp.rds"))

ggplot(relf, aes(x=name, y=value, fill=Component)) +
    geom_violin(scale="width")
```

```{r}
select(fit.g1, threshold = 0.95)
```

```{r}
threshold_density <- function(x) {stats::dbeta(x, 20, 2)}
s <- select.integrate(fit.g1, p = threshold_density)
print(s$expected)
```

```{r}
t <- seq(1, 55, by = 1)
x_pred <- new_x(lgpinput, t, x="day", x_ns = "recoveryonset")
p <- pred(fit.g1, x_pred, reduce = mean)
plot_pred(fit.g1, x = x_pred, pred = p, t_name="day", group_by=c("id"))
```

```{r}
plot_f(fit.g1, x = x_pred, pred = p, t_name="day",  color_by="pred_evo")
```

```{r}
plot_components(fit.g1,
                x = x_pred, 
                t_name = "day",
                group_by="id", 
                pred = p,
                color_by = c(NA, NA, "pred", "evo", "pred_evo", NA, "pred_evo"),
                #color_by="pred_evo",
                ylim = c(-3,2))
```

# DATA FOR PLOTTING

## SUM FUNCTION PLUS DATA ON ORIGINAL DATA SCALE
```{r}
input <- lgpr:::plot_pred.create_input(fit.g1, p, x_pred, draws, reduce, "id", "day")

data <- lgpr:::create_plot_df(fit.g1, x="day") %>%
  mutate(y=10^y) %>% dplyr::rename(obs=y)

rib <- lgpr:::plot_pred.create.df_ribbon(fit.g1, p, lgpr:::dollar(input, "df_base"), 2) %>%
  mutate(upper=10^upper,
         lower=10^lower)

lines <- lgpr:::plot_pred.create.df_line(fit.g1, p, lgpr:::dollar(input, "df_base")) %>%
  mutate(y=10^y)

atpfinal <- left_join(lines, rib) %>%
  left_join(., data) %>%
  mutate(measure="atp") %>%
  left_join(., distinct(dplyr::select(lgpinput, pred, evo, pred_evo, id)))

saveRDS(atpfinal, here::here("output", "data_atp.rds"))

ggplot(atpfinal, aes(x=day, group=id)) + 
  geom_ribbon(aes(ymax=upper, ymin=lower), alpha=0.1) +
  geom_line(aes(y=y, color=pred_evo)) +
  geom_point(aes(y=obs, color=pred_evo)) +
  scale_y_log10() +
  facet_wrap(~id) +
  theme_bw()
```

## INDIVIDUAL COMPONENTS
```{r}

# 1. time is shared
vardata1 <- left_join(lgpr:::plot_f.create.df_ribbon(fit.g1, p, lgpr:::dollar(input, "df_base"), comp_idx=1, 2),
                 lgpr:::plot_f.create.df_line(fit.g1, p, lgpr:::dollar(input, "df_base"), comp_idx=1)) %>%
  mutate(variable="day") %>%
  dplyr::select(-id) %>% dplyr::distinct()

# pred_evo
vardata5 <- left_join(lgpr:::plot_f.create.df_ribbon(fit.g1, p, lgpr:::dollar(input, "df_base"), comp_idx=5, 2),
                 lgpr:::plot_f.create.df_line(fit.g1, p, lgpr:::dollar(input, "df_base"), comp_idx=5)) %>%
  mutate(variable="pred_evo") %>%
  left_join(., distinct(dplyr::select(lgpinput, pred_evo, id))) %>%
  dplyr::select(-id) %>% dplyr::distinct()

# 6. recovery is shared
vardata6 <- left_join(lgpr:::plot_f.create.df_ribbon(fit.g1, p, lgpr:::dollar(input, "df_base"), comp_idx=6, 2),
                 lgpr:::plot_f.create.df_line(fit.g1, p, lgpr:::dollar(input, "df_base"), comp_idx=6)) %>%
  mutate(variable="recovery") %>%
  dplyr::select(-id) %>% dplyr::distinct()

vardataf <- bind_rows(vardata1, vardata5, vardata6)

saveRDS(vardataf, here::here("output", "vars_atp.rds"))

ggplot(vardataf, aes(x=day, y=y, ymax=upper, ymin=lower, fill=pred_evo, color=pred_evo)) + 
  geom_ribbon(alpha=0.25) +
  geom_line() +
  facet_wrap(~variable) +
  theme_bw()
```
